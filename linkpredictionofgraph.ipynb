{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanksha0911/Graph-neural-networks-/blob/main/linkpredictionofgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Purpose** : how to train a GNN for link prediction, i.e. predicting the existence of an edge between two arbitrary nodes in a graph.\n",
        "\n",
        "---\n",
        "**Build a GNN-based link prediction model.**\n",
        "\n",
        "**Train and evaluate the model on Cora Dataset**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "One of the cool things about the PyTorch Geometric library is that it contains out-of-the-box benchmark datasets that are ready to use and explore. A popular dataset is the Cora dataset.\n",
        "\n",
        "\"The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\" - Papers with Code.\n",
        "\n"
      ],
      "metadata": {
        "id": "xTtME2_C7pBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UseCase of link prediction:\n",
        "---\n",
        "Many applications such as social recommendation, item recommendation, knowledge graph completion, etc., can be formulated as link prediction, which predicts whether an edge exists between two particular nodes."
      ],
      "metadata": {
        "id": "97CYSJegBthR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9xbOgJG8S1R",
        "outputId": "cb130d23-9114-4763-d434-8f5b77b392b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.9 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset = Planetoid(root='tmp/Cora', name='Cora')\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFPdmlV19J5H",
        "outputId": "7447c424-b78e-4f32-f8b5-c81e367394fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "===========================================================================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4YbSqKbl-aF"
      },
      "source": [
        "# GAE for link prediction\n",
        "\n",
        "[code](https://github.com/rusty1s/pytorch_geometric/blob/master/examples/link_pred.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges"
      ],
      "metadata": {
        "id": "wccTIN9HAVwU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R5DGmPOLl-aH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c716f64-e76a-4062-fd01-3b2f7229ea55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2708, 1433], val_pos_edge_index=[2, 263], test_pos_edge_index=[2, 527], train_pos_edge_index=[2, 8976], train_neg_adj_mask=[2708, 2708], val_neg_edge_index=[2, 263], test_neg_edge_index=[2, 527])\n"
          ]
        }
      ],
      "source": [
        "# use train_test_split_edges to create neg and positive edges\n",
        "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
        "data = train_test_split_edges(data)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZBFZOyOl-aI"
      },
      "source": [
        "#### Simple autoencoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Do2CrVExl-aI"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, 128)\n",
        "        self.conv2 = GCNConv(128, 64)\n",
        "\n",
        "    def encode(self):\n",
        "        x = self.conv1(data.x, data.train_pos_edge_index) # convolution 1\n",
        "        x = x.relu()\n",
        "        return self.conv2(x, data.train_pos_edge_index) # convolution 2\n",
        "\n",
        "    def decode(self, z, pos_edge_index, neg_edge_index): # only pos and neg edges\n",
        "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
        "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
        "        return logits\n",
        "\n",
        "    def decode_all(self, z): \n",
        "        prob_adj = z @ z.t() # get adj NxN\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t() # get predicted edge_list "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = \"cpu\""
      ],
      "metadata": {
        "id": "E57ncmSNAmsS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AR4ij17El-aJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gNOyWNCEl-aK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_link_labels(pos_edge_index, neg_edge_index):\n",
        "    # returns a tensor:\n",
        "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the lenght of pos_edge_index\n",
        "    # and the number of zeros is equal to the length of neg_edge_index\n",
        "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
        "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
        "    link_labels[:pos_edge_index.size(1)] = 1.\n",
        "    return link_labels\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=data.train_pos_edge_index, #positive edges\n",
        "        num_nodes=data.num_nodes, # number of nodes\n",
        "        num_neg_samples=data.train_pos_edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    z = model.encode() #encode\n",
        "    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index) # decode\n",
        "    \n",
        "    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index)\n",
        "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    perfs = []\n",
        "    for prefix in [\"val\", \"test\"]:\n",
        "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
        "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
        "\n",
        "        z = model.encode() # encode train\n",
        "        link_logits = model.decode(z, pos_edge_index, neg_edge_index) # decode test or val\n",
        "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
        "        \n",
        "        link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
        "        \n",
        "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score\n",
        "    return perfs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pLvED-_Kl-aL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198667d3-dd11-450a-a047-1a818ab53c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.6316, Val: 0.8368, Test: 0.8115\n",
            "Epoch: 020, Loss: 0.5081, Val: 0.8937, Test: 0.8630\n",
            "Epoch: 030, Loss: 0.4584, Val: 0.9259, Test: 0.8933\n",
            "Epoch: 040, Loss: 0.4325, Val: 0.9344, Test: 0.8995\n",
            "Epoch: 050, Loss: 0.4221, Val: 0.9381, Test: 0.9021\n",
            "Epoch: 060, Loss: 0.4136, Val: 0.9386, Test: 0.9020\n",
            "Epoch: 070, Loss: 0.4069, Val: 0.9386, Test: 0.9020\n",
            "Epoch: 080, Loss: 0.4006, Val: 0.9386, Test: 0.9020\n",
            "Epoch: 090, Loss: 0.4005, Val: 0.9386, Test: 0.9020\n",
            "Epoch: 100, Loss: 0.3928, Val: 0.9386, Test: 0.9020\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_val_perf = test_perf = 0\n",
        "for epoch in range(1, 101):\n",
        "    train_loss = train()\n",
        "    val_perf, tmp_test_perf = test()\n",
        "    if val_perf > best_val_perf:\n",
        "        best_val_perf = val_perf\n",
        "        test_perf = tmp_test_perf\n",
        "    log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "    if epoch % 10 == 0:\n",
        "        print(log.format(epoch, train_loss, best_val_perf, test_perf))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4gqdd6Oml-aL"
      },
      "outputs": [],
      "source": [
        "z = model.encode()\n",
        "final_edge_index = model.decode_all(z)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvkGxNSWBYfZ",
        "outputId": "cfb79539-5a35-426e-d637-7e9044ac1131"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
              "        [   0,    1,    2,  ..., 2705, 2706, 2707]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}